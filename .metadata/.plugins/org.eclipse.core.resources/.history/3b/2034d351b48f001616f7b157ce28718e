

import org.apache.spark.rdd.RDD
import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
object reduceTest {
  
  def main(args: Array[String]): Unit = {
    val conf=new SparkConf
    conf.setMaster("local[2]").setAppName("WORDCOUNT")
    val sc=new SparkContext(conf)
    val first = sc.parallelize(List("dog", "salmon", "salmon", "rat", "elephant"), 3)
    val result=first.reduce((a,b)=>join(a,b))
    result.foreach { n => print(n) }
  }
  def join(a:String,b:String):String=
  {
    a+"_"+b
  }
  
}